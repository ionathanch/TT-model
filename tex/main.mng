\newif\ifarxiv
\arxivtrue

\documentclass[a4paper,UKenglish,cleveref,autoref,thm-restate]{lipics-v2021}

\ifarxiv
\pdfoutput=1
\usepackage[T1]{fontenc}
\else
\usepackage{fontspec}
\fi

\usepackage[supertabular]{ottalt}
\let\newlist\relax
\let\renewlist\relax
\usepackage{enumitem,booktabs,xspace,doi}
\usepackage{mathpartir,mathtools,stmaryrd}
\usepackage[bottom,flushmargin,multiple,para]{footmisc} % para spacing is weird and ugly
\usepackage[scale=0.92]{inconsolata}
% \setmonofont[Scale=MatchUppercase]{sgr-iosevka-fixed-regular.ttc}

\newcommand{\citep}[1]{\cite{#1}}
\newcommand{\citet}[1]{\cite{#1}}
\newcommand{\repo}{https://github.com/ionathanch/TTBFL}
\newcommand{\lang}{TTBFL\@\xspace}
\newcommand{\titlebreak}{\texorpdfstring{\\}{}}
\newcommand{\ie}{\textit{i.e.}\@\xspace}
\newcommand{\eg}{\textit{e.g.}\@\xspace}
\newcommand{\etal}{\textit{et al.}\@\xspace}
\newcommand{\vs}{\textit{vs.}\@\xspace}
\newcommand{\ala}{\textit{\`a la}\@\xspace}
\newcommand{\apriori}{\textit{a priori}\@\xspace}
\newcommand{\fstar}{F$^\star$\@\xspace}
\newcommand{\welltyped}{well-\hspace{0pt}typed\@\xspace}
\newcommand{\wellfounded}{well-\hspace{0pt}founded\@\xspace}
\newcommand{\wellfoundedness}{well-\hspace{0pt}foundedness\@\xspace}
\newcommand{\wellformedness}{well-\hspace{0pt}formedness\@\xspace}
\newcommand{\welldefinedness}{well-\hspace{0pt}definedness\@\xspace}
\newcommand{\crude}{crude-\hspace{0pt}but-\hspace{0pt}effective\@\xspace}

\newcommand{\thmref}[2]{%
  $\langle$\textnormal{\texttt{\href{\repo/tree/main/src/#1}{#1}:#2}}$\rangle$%
}

\setlength{\fboxsep}{2pt}
\setlength{\abovecaptionskip}{0\baselineskip}
\setlength{\textfloatsep}{\baselineskip}
\setlength{\intextsep}{0.25\baselineskip}
\setlength{\jot}{0\baselineskip}

\hypersetup{
  colorlinks=true,
  urlcolor=blue,
  linkcolor=magenta,
  citecolor=teal
}
\urlstyle{tt}

\title{Bounded First-Class Universe Levels \titlebreak in Dependent Type Theory}
\titlerunning{Bounded First-Class Universe Levels}
\authorrunning{J. Chan, S. Weirich}
\Copyright{Jonathan Chan, Stephanie Weirich}
\ccsdesc{Theory of computation~Type theory}
\keywords{type theory, universes, universe polymorphism}
\hideLIPIcs

\author{Jonathan Chan}
  {University of Pennsylvania, Philadelphia, USA}
  {jcxz@seas.upenn.edu}
  {0000-0003-0830-3180}
  {}

\author{Stephanie Weirich}
  {University of Pennsylvania, Philadelphia, USA}
  {sweirich@seas.upenn.edu}
  {0000-0002-6756-9168}
  {}

\supplementdetails[subcategory={source code},
  swhid={swh:1:dir:8f18b01234056282a037b3d835e97df2b5050b29} % see https://archive.softwareheritage.org/
]{Software}{\repo}

\inputott{rules}

% \acknowledgements{hi \href{https://types.pl}{\texttt{types.pl}}!}

\begin{document}

\setlength{\abovedisplayskip}{0.25\baselineskip}
\setlength{\belowdisplayskip}{0.25\baselineskip}

\maketitle

\begin{abstract}
  In dependent type theory,
  being able to refer to a type universe as a term itself increases its expressive power,
  but requires mechanisms in place to prevent Girard's paradox
  from introducing logical inconsistency in the presence of type-in-type.
  The simplest mechanism is a hierarchy of universes indexed by a sequence of levels,
  typically the naturals.
  To improve reusability of definitions, they can be made level polymorphic,
  abstracting over level variables and adding a notion of level expressions.
  For even more expressive power,
  level expressions can be made first-class as terms themselves,
  and level polymorphism is subsumed by dependent functions quantifying over levels.
  Furthermore, bounded level polymorphism provides more expressivity
  by being able to explicitly state constraints on level variables.
  While semantics for first-class levels with constraints are known,
  syntax and typing rules have not been explicitly written down.
  Yet pinning down a well-behaved syntax is not trivial;
  there exist prior type theories with bounded level polymorphism
  that fail to satisfy subject reduction.
  In this work, we design an explicit syntax for
  a type theory with bounded first-class levels,
  parametrized over arbitrary well-founded sets of levels.
  We prove the metatheoretic properties of subject reduction,
  type safety, consistency, and canonicity,
  entirely mechanized from syntax to semantics in Lean.
\end{abstract}

\section{Introduction}

Dependent type theories are common foundations for proof assistants,
where theorems are manipulated as types and their proofs as terms.
Types are often treated as terms themselves,
providing a uniform mechanism for working with both;
for example, quantifying over predicates is no different from quantifying over functions,
as predicates are functions that return types.
To merge types and terms, we need a type of types, or a \emph{universe},
which itself must be a term with a type.

Girard~\citep{systemf} showed that a type-in-type axiom makes dependent type theory logically inconsistent:
if the type of a universe is itself, then all types are inhabited,
rendering the type theory useless as a tool for proving.
Therefore, Martin-L\"of stratified the universe in his type theory (MLTT)~\citep{mltt}
into a countably infinite hierarchy of universes
$[[U 0]] : [[U 1]] : [[U 2]] : \dots$
indexed by \emph{universe levels} spanning the naturals.
Many contemporary proof assistants based on dependent types feature such a hierarchy,
such as Rocq~\citep{rocq}, Agda~\citep{agda}, Lean~\citep{lean}, and F$^\star$~\citep{fstar}.

Having only a concrete universe hierarchy, however,
limits the reusability of definitions that are not inherently tied to particular universe levels.
For example, the identity function $\kw{id} : [[:concrete: ΠA: U i. A → A]]$
would need to be redefined for each universe level $[[i]]$ at which it is needed.
Universe level polymorphism addresses this issue by abstracting over level variables,
used to index universes alongside concrete levels.
Its simplest form is prenex level polymorphism,
introduced by Harper and Pollack~\citep{anon-univ},
which restricts the abstraction to top-level definitions.
Courant~\citep{explicit} extends their implicit system to an explicit system
with (in)equality constraints, level operators, and level expressions.
This extension is implemented in Rocq~\citep{univ-poly-coq}.

If we disallow recursive definitions that vary in the level,
uses of prenex-polymorphic definitions
can be specialized to level-monomorphic terms.
Favonia, Angiuli, and Mullanix note that it
``is as consistent as standard (monomorphic) type theory [\dots]
because any given proof can only mention finitely many universes'',
and show consistency using this idea~\citep{displacement}.

If level quantification is added as a type former directly to the type theory,
we obtain higher-rank level polymorphism,
where level-polymorphic terms can be passed as arguments to functions.
For instance, Bezem, Coquand, Dybjer, and Escard\'o
introduce such a type theory (referred to here as BCDE)
with level constraints~\citep{univ-poly}.
Going further, rather than keeping universe levels distinct from terms,
we can make them first class by defining level expressions as a subset of terms,
and add a type of levels;
such levels are found in Agda.
Level quantification is subsumed by dependent functions whose domain is this level type.
The codomain can also be the level type,
which describes functions that compute levels.

First-class universe levels are known to be logically consistent.
In particular, Kov\'{a}cs~\citep{gen-univ} gives a semantic model for a type theory TTFL,
which features first-class levels and an ordering relation $<$ on them.
The model is given as categories with families (cwfs)~\citep{cwf},
mostly mechanized in Agda using induction--recursion,
and supports features such as level constraints,
maxima of levels, and induction on levels.

The syntax of TTFL is considered to be the initial model in the category of cwfs,
but an explicit syntax and typing rules are not given,
and proving initiality even for MLTT is a colossal task~\citep{initiality}.
Furthermore, while a syntax may satisfy semantic properties such as logical consistency,
it may not necessarily satisfy desirable syntactic properties.
In particular, BCDE's semantics can conceivably be viewed as
that of TTFL without making levels first class,
yet its syntax fails to satisfy subject reduction.

In this work, we give an end-to-end account of first-class levels in type theory,
beginning with an explicit syntax and typing rules,
and proving that they satisfy desirable metatheoretic properties.
Our contributions are as follows:

\begin{itemize}[topsep=0pt]
  \item We present \textbf{\lang},
    a dependent type theory with bounded, first-class universe levels.
    Our bounds differ from level constraints in that
    they are inherent to the type of a level,
    rather than a separate predicate on them,
    which prevents failure of subject reduction.
    Examples in the next section build up from monomorphic levels to level polymorphism
    before we proceed to the formal definition of the type theory in \cref{sec:ttbfl}.
  \item We prove subject reduction (\ie preservation) in \cref{sec:safety},
    an improvement upon the metatheoretic properties of BCDE.
    We also prove progress and thus type safety,
    which is important if we also want to use the language for writing programs that evaluate.
    An example is implementing proof assistants in themselves,
    as is (partially) done in Lean and undergoing work for Rocq~\citep{coq-in-coq}.
  \item Using a syntactic logical relation,
    we prove logical consistency and canonicity
    via the fundamental soundness theorem in \cref{sec:lr}.
    Consistency ensures that the type theory is suitable
    as a basis for logical reasoning in a proof assistant,
    while canonicity ensures that closed terms evaluate to the values we expect.
    Normalization of open terms remains an open problem (\cref{sec:normalization}).
\end{itemize}
%
All results are mechanized in Lean.
The development consists of under 1600 lines of code,
which can be found in the supplementary materials at \url{\repo}.
The definitions and theorems in this paper
are hyperlinked to the corresponding Lean files.

As our system is intentionally very minimal,
we discuss some further extensions in \cref{sec:extensions},
including level operators and subtyping.
We conclude with future work in \cref{sec:conclusion}.

\section{Motivation}

To motivate the range of features in \lang,
we look at examples starting from monomorphic universe levels
and build up to first-class levels and bounding in this section.
Although not found in our minimal language,
these examples use dependent pairs, propositional equality, the naturals, and lists
for more illuminating examples.

Let us start by revisiting the identity function and its type,
supposing $[[U 0]] : [[U 1]] : \dots [[U o]]$,
with a limit universe $[[o]]$ at the top,
which will come in handy later.
%
\begin{align*}
  [[!Id]] &: [[U 1]]
  &[[!id]] &: [[!Id]] \\
  [[!Id]] &\coloneqq [[:concrete: ΠA : U 0. A → A]]
  & [[!id]] &\coloneqq [[:concrete: λA : U 0. λx : A. x]]
\end{align*}

This identity function is polymorphic over types in $[[U 0]]$,
but not over universes, so the self application
$[[!id !Id !id]]$ is ill typed.
More generally, if we want to reuse a definition at different universe levels,
it would need to be redefined for every level needed.
If we introduce prenex polymorphism of universe levels,
where top-level definitions are permitted to be polymorphic,
we can write a universe polymorphic identity function
that can be instantiated at different levels and self-applied.
%
\begin{align*}
  [[!Id]] &: [[:concrete: ∀i. U (# i++ #)]]
  &[[!id]] &: [[:concrete: ∀i. !Id [i] ]] \\
  [[!Id]] &\coloneqq [[:concrete: Λi. ΠA : U i. A → A]]
  &[[!id]] &\coloneqq [[:concrete: Λi. λA : U i. λx : A. x]]
\end{align*}

Now, the expression $[[!id [1] (!Id [0]) (!id [0])]]$ is well typed.
A definition can also be polymorphic over multiple levels,
such as the constant function that takes two arguments but always returns the first.
For this, we need a binary least upper bound operator $[[_ ⊔ _]]$ on levels.
%
\begin{align*}
  [[!Const]] &: [[:concrete: ∀i. ∀j. U (# (i ⊔ j)++ #)]]
  &[[!const]] &: [[:concrete: ∀i. ∀j. !Const [i] [j] ]] \\
  [[!Const]] &\coloneqq [[:concrete: Λi. Λj. ΠA : U i. ΠB : U j. A → B → A]]
  &[[!const]] &\coloneqq [[:concrete: Λi. Λj. λA. λB. λx. λy. x]]
\end{align*}

The universe in which $[[!Const [i] [j] ]]$ lives is $[[(i ⊔ j)++]]$,
because its universe must contain the universes
$[[U i]]$ and $[[U j]]$ over which it quantifies.
As more level variables get involved,
the algebraic expressions on levels becomes increasingly complex.
But the precise universe in which $[[!Const]]$ lives is not as important
as knowing that it lives in \emph{some} greater universe,
which is all that is needed to prevent type-in-type inconsistencies.
This can be expressed by bounded level quantification,
simplifying level expressions at the cost of an additional level variable.
We use the limit level $[[o]]$ to allow $[[k]]$ to range over all other levels.
%
\begin{align*}
  [[!Const]] &: [[:concrete: ∀k < o. ∀i < k. ∀j < k. U k]] \\
  [[!Const]] &\coloneqq [[:concrete: Λk. Λi. Λj. ΠA : U i. Π B : U j. A → B → A]]
\end{align*}

While nonrecursive prenex level polymorphism can be monomorphized away,
this is not the case once we introduce recursive definitions
whose recursive calls may vary in the level.
This lets us define universes with levels incremented by fixed amount,
\ie $[[:concrete: U (# k + n #)]]$.
%
\begin{align*}
  &[[!incr]] : [[:concrete: ∀k < o. !Nat → U o]] \\
  &[[!incr k !zero]] \coloneqq [[:concrete: U k]] \\
  &[[!incr k (!succ n)]] \coloneqq [[!incr n [k++] ]]
\end{align*}

Generalizing from prenex level polymorphism to higher-rank level polymorphism affords even more reusability.
One application is when axioms are explicitly assumed
as local hypotheses instead of globally axiomatized
to restrict their usage to only where they are really needed.
An example is function extensionality,
whose type is level polymorphic.
%
\begin{align*}
  [[!FunExt]] &: [[:concrete: ∀k < o. ∀i < k. ∀j < k. U k]] \\
  [[!FunExt]] &\coloneqq [[:concrete: Λk. Λi. Λj. ΠA : U i. Π B : (A → U j). _]] \\
  &\phantom{{} \coloneqq {}} [[:concrete: Πf : (Πx : A. B x). Πg : (Πx : A. B x). (Πx : A. f x = g x) → (# f = g #)]]
\end{align*}

Suppose we wished to prove that function extensionality for
functions with two arguments at different universe levels follows from assuming $[[!FunExt]]$.
Using only prenex polymorphism, we would need two separate instantiations,
once for its application to the functions of type $[[Πx : A. B x → C x]]$,
and once for its application to the functions of type $[[B x → C x]]$.
%
\begin{align*}
  [[!lemma]] &: [[:concrete: ∀l < o. ∀i < l. ∀j < l. ∀k < l. (!FunExt [l] [i] [j ⊔ k]) → (!Funext [l] [j] [k]) → _]] \\
  &\phantom{{} : {}} [[:concrete: ΠA : U i. ΠB : (A → U j). ΠC : (A → U k). _]] \\
  &\phantom{{} : {}} [[:concrete: Πf : (Πx : A. B x → C x). Πg : (Πx : A. B x → C x). _]] \\
  &\phantom{{} : {}} [[:concrete: (Πx : A. Πy : B x. f x y = g x y) → (# f = g #)]] \\
  [[!lemma]] &\coloneqq [[:concrete: Λl. Λi. Λj. Λk. λfe1. λfe2. _]] \dots
\end{align*}

Once more universe levels get involved,
instantiating up front every possible use becomes unwieldy.
With higher-rank polymorphism,
we can quantify over a polymorphic function extensionality principle once and for all,
and instantiate its levels within the proof as needed.
%
\begin{align*}
  [[!lemma]] &: [[:concrete: (∀k < o. ∀i < k. ∀j < k. !FunExt [i] [j] [k]) → _]] \\
  &\phantom{{} : {}} [[:concrete: ∀l < o. ∀i < l. ∀j < l. ∀k < l. ΠA : U i. ΠB : (A → U j). ΠC : (A → U k). _]] \\
  &\phantom{{} : {}} [[:concrete: Πf : (Πx : A. B x → C x). Πg : (Πx : A. B x → C x). _]] \\
  &\phantom{{} : {}} [[:concrete: (Πx : A. Πy : B x. f x y = g x y) → (# f = g #)]] \\
  [[!lemma]] &\coloneqq [[:concrete: λfe. Λl. Λi. Λj. Λk. _]] \dots
\end{align*}

With higher-rank level polymorphism,
a level-polymorphic type itself must live in some universe,
which is often that of the bounding level.
Coming back to the identity function,
we can impose a bound on its level by bounded quantification,
and use the bound for the universe.
Self-applications such as $[[!id [2] [1] (!Id [1]) (!id [1])]]$ still hold.
%
\begin{align*}
  [[!Id]] &: [[:concrete: ∀j < o. U j]] &
  [[!id]] &: [[:concrete: ∀j < o. !Id [j] ]] \\
  [[!Id]] &\coloneqq [[:concrete: Λj. ∀i < j. ΠA : U i. A → A]] &
  [[!id]] &\coloneqq [[:concrete: Λj. Λi. λA : U i. λx : A. x]]
\end{align*}

So far, our notions of level polymorphism treat levels as syntactically separate from terms,
with special level operators $\cdot [[_ ++]]$ and $\cdot [[_ ⊔ _]] \cdot$.
Consequently, if we want more general ways to compute level expressions,
we must add them as primitives to the language.
If we instead make levels first class,
we are then able to manipulate and store them as terms.
Bounded level quantifications are subsumed by ordinary dependent types
whose domain is the type of all levels bounded by some strictly greater level $[[Level< k]]$.
An example application is computing the least upper bound level
from a list of levels and types of that level.
%
\begin{align*}
  [[!lub]] &: [[:concrete: !List (Σi : Level< o. Type i) → Level< o]] \\
  [[!lub]] &\gap [[!nil]] \coloneqq 0 \\
  [[!lub]] &\gap [[(!cons (i, A) As)]] \coloneqq [[i ⊔ (!lub As)]]
\end{align*}

This level computation can be used to turn a list of types and their levels
into an n-ary tuple with a precise level.
This is a technique used, for instance, by Escot and Cockx in generic programming
to represent level-polymorphic inductive types~\citep{generic}.
%
\begin{align*}
  [[!Interp]] &: [[:concrete: ΠAs : !List (Σi : Level< o. Type i). Type (!lub As)]] \\
  [[!Interp]] &\gap [[!nil]] \coloneqq [[⊤]] \\
  [[!Interp]] &\gap [[(!cons (i, A) As)]] \coloneqq [[A × (!Interp As)]]
\end{align*}

Various proof assistants with universe level polymorphism implement different subsets of these features.
Lean and F$^\star$ have prenex polymorphism with successor and least upper bound operators.
Rocq has prenex polymorphism along with level (in)equality declarations,
but no other operators.
Agda has first-class levels and the two level operator, but no level constraints.
In \lang, we include bounded first-class levels,
but omit the two level operators for simplicity,
opting to treat them as straightforward potential extensions.

\section{A minimal type theory with bounded first-class universe levels} \label{sec:ttbfl}

\lang is a Church-style type theory \ala Russell,
where terms may have type annotations,
and there is no separate typing judgement for well-formedness of types.
To keep the type theory minimal, it contains only dependent functions,
an empty type, predicative universes, and bounded universe levels.
By convention, we use $[[a]], [[b]], [[c]]$ for terms,
$[[A]], [[B]], [[C]]$ for types,
and $[[k]], [[l]]$ for level terms.
The syntax is presented in \cref{fig:syntax};
we additionally use $[[A → B]]$ as sugar for nondependent functions
$[[Πx : A. B]]$ where $[[x]]$ does not occur in $[[B]]$.
While the mechanization uses de Bruijn indexing and simultaneous substitutions,
this paper presents the syntax in nominal form for clarity,
and we omit the details of manipulating substitutions for concision.
We write single substitutions of a variable $[[x]]$
in a term $[[b]]$ by another term $[[a]]$ as $[[b{x ↦ a}]]$.

\begin{figure}
\vspace{-\baselineskip}
\begin{align*}
  i, j & \Coloneqq \texttt{<concrete universe levels>} \\
  x, y, z & \Coloneqq \texttt{<term variables>} \\
  a, b, c, A, B, C, k, \ell & \Coloneqq [[x]] \mid [[i]]
    \mid [[Πx : A. B]] \mid [[λx : A. b]] \mid [[b a]]
    \mid [[⊥]] \mid [[abs' A b]]
    \mid [[Type k]] \mid [[Level< l]] \\
  [[G]], [[D]] & \Coloneqq [[•]] \mid [[G, x : A]]
\end{align*}
\caption{Syntax \thmref{syntactics.lean}{Term,Ctxt}}
\label{fig:syntax}
\end{figure}

The type theory is parametrized over a cofinal woset of levels,
\ie a set of levels that are well founded, totally ordered,
and each have some strictly larger level;
these properties are required when modelling the type theory.
Instances of such sets include the naturals $0, 1, 2, \dots$,
as well as the naturals extended by one limit ordinal $\omega$
and its successors $\omega + 1, \omega + 2, \dots$.
We continue to use these concrete levels for our examples.
These metalevel levels are internalized directly in system as terms $[[i]]$.

\begin{figure}
\begin{mathpar}
  \inferrule[\ottdrulename{Nil}]{~}{[[⊢ •]]}
  \and
  \inferrule[\ottdrulename{Cons}]
    {[[⊢ G]] \and
     [[G ⊢ A : Type k]]}
    %------------------%
    {[[⊢ G, x : A]]}
  \and
  \inferrule[\ottdrulename{Var}]
    {[[⊢ G]] \and
     [[x : A ∈ G]]}
    %-------------%
    {[[G ⊢ x : A]]}
  \and
  \inferrule[\ottdrulename{Pi}]
    {[[G ⊢ A : Type k]] \and
     [[G, x : A ⊢ B : Type k]]}
    %--------------------------%
    {[[G ⊢ Πx : A. B : Type k]]}
  \and
  \inferrule[\ottdrulename{Lam}]
    {[[G ⊢ A : Type k]] \and
     [[G ⊢ Πx : A. B : Type k]] \and
     [[G, x : A ⊢ b : B]]}
    %-----------------------------%
    {[[G ⊢ λx : A. b : Πx : A. B]]}
  \and
  \inferrule[\ottdrulename{App}]
    {[[G ⊢ b : Πx : A. B]] \and
     [[G ⊢ a : A]]}
    %----------------------%
    {[[G ⊢ b a : B{x ↦ a}]]}
  \and
  \inferrule[\ottdrulename{Mty}]
    {[[G ⊢ Type k : Type l]]}
    %-----------------------%
    {[[G ⊢ ⊥ : Type k]]}
  \and
  \inferrule[\ottdrulename{Abs}]
    {[[G ⊢ A : Type k]] \and
     [[G ⊢ b : ⊥]]}
    %--------------------%
    {[[G ⊢ abs' A b : A]]}
  \and
  \inferrule[\ottdrulename{Conv}]
    {[[G ⊢ a : A]] \and
     [[G ⊢ B : Type k]] \and
     [[A = B]]}
    %------------------%
    {[[G ⊢ a : B]]}
\end{mathpar}
%
\begin{mathpar}
  \inferrule[\ottdrulename{E-Beta}]{~}{[[(λx : A. b) a = b{x ↦ a}]]} \and
  \inferrule[\ottdrulename{E-Refl}]{~}{[[a = a]]} \and
  \inferrule[\ottdrulename{E-Sym}]{[[a = b]]}{[[b = a]]} \and
  \inferrule[\ottdrulename{E-Trans}]{[[a = b]] \and [[b = c]]}{[[a = c]]} \and
  \cdots
\end{mathpar}
\caption{Typing and selected equality rules (no universes or levels) \thmref{typing.lean}{Wtf,Eqv}}
\label{fig:typing:basic}
\end{figure}

We begin first with the basic rules that don't concern universes or levels in \cref{fig:typing:basic},
consisting of a context well-formedness judgement \fbox{$[[⊢ G]]$},
a typing judgement \fbox{$[[G ⊢ a : A]]$},
and an untyped definitional equality \fbox{$[[a = b]]$}.
We use $\beta$-conversion as our equality,
and omit the usual congruence rules.
Unusually, \rref{Lam} includes well-typedness premises 
of both the function's type and the domain type alone.
The former is necessary to strengthen the induction hypotheses
when proving the fundamental soundness theorem,
and the latter to strengthen them when proving subject reduction.
We later prove admissible a rule \nameref{Lam'} that omits the first premise.
The other typing rules are otherwise typical.

\begin{figure}
\begin{mathpar}
  \inferrule*[right=\ottdrulename{Univ}]
    {[[G ⊢ k : Level< l]]}
    %-----------------------%
    {[[G ⊢ Type k : Type l]]}
  \quad
  \inferrule*[right=\ottdrulename{Level<}]
    {[[G ⊢ Type k1 : Type l1]] \and
     [[G ⊢ k0 : Level< l0]]}
    %---------------------------%
    {[[G ⊢ Level< k0 : Type k1]]}
  \quad
  \inferrule*[right=\ottdrulename{Lvl}]
    {[[⊢ G]] \and
     [[i < j]]}
    %--------------------%
    {[[G ⊢ i : Level< j]]}
  \and
  \inferrule*[right=\ottdrulename{Trans}]
    {[[G ⊢ k1 : Level< k2]] \and
     [[G ⊢ k2 : Level< k3]]}
    %----------------------%
    {[[G ⊢ k1 : Level< k3]]}
  \and
  \inferrule*[right=\ottdrulename{Cumul}]
    {[[G ⊢ A : Type k]] \and
     [[G ⊢ k : Level< l]]}
    %--------------------%
    {[[G ⊢ A : Type l]]}
\end{mathpar}
\caption{Typing rules (universes and levels)}
\label{fig:typing:univ}
\end{figure}

The rules relating to universes and levels are given in \cref{fig:typing:univ}.
By \rref{Lvl}, we can view the type constructor $[[Level< _]]$
as a restricted internalization of the order on levels.
Quantifications and abstractions over a level variable
must be bounded by some level expression,
which cannot be the variable itself since it is not in the scope of its own type.
In contrast, if we had more general level constraint types,
it would be possible to declare a looping constraint $[[x]] < [[x]]$.
The level type itself can be typed at any universe by \rref{Level<}
regardless of its bounding level.
For example, we can construct a derivation for $[[• ⊢ Level< 2 : Type 0]]$
solely knowing that $[[• ⊢ 2 : Level< 3]]$, $[[• ⊢ Type 0 : Type 1]]$,
which follow from $[[0 < 1]]$ and $[[2 < 3]]$.

\Rref{Trans} internalizes transitivity of the order on levels,
which is now required since levels are terms in general and not only concrete levels.
For example, we can construct a derivation for $[[x : Level< o, y : Level< x ⊢ x : Level< o]]$,
where the levels $[[x]], [[y]]$ are variables.
\Rref{Cumul} is a cumulativity rule that permits lifting a type
from one universe to a higher universe.
This rule is weaker than a full subtyping rule that accounts for
contravariance in the domain and covariance in the codomain of function types.
Therefore, for instance, $[[f : Type 2 → Type 0 ⊢ f : Type 1 → Type 1]]$ does \emph{not} hold.
Nonetheless, cumulativity allows us to instead type the $\eta$-expansion
$[[f : Type 2 → Type 0 ⊢ λx : Type 1. f x : Type 1 → Type 1]]$.

Finally, \rref{Univ} asserts that a universe at level $[[k]]$
lives in the universe at level $[[l]]$ when $[[k]]$ is strictly bounded by $[[l]]$.
Allowing universes with general level terms and not just concrete levels
to be well typed is what permits typing level-polymorphic types.
For example, the level-polymorphic identity function type
$[[Πx : Level< o. Πy : Type x. y → y]]$ is typeable.
$[[Level< o]]$ can be assigned an arbitrary type by \rref{Level},
$[[Type x]]$ has type $[[Type o]]$ by \rref{Univ} and \rref{Var},
and $[[y]]$ can be assigned type $[[Type o]]$ transitively via \rref{Trans,Var}.
Then the entire term has type $[[Type o]]$ by repeated application of \rref{Pi}.

\section{Type safety} \label{sec:safety}

Type safety is proven using standard syntactic methods
to show progress and preservation (\ie subject reduction).
In essence, closed, well-typed terms evaluate (if they terminate) to values,
which are type formers and constructors,
defined below.
The proof is standard, so we omit most details,
listing only some of the key lemmas required.
\begin{equation*}
  [[v]] \Coloneqq [[i]] \mid [[Πx : A. B]] \mid [[λx : A. b]] \mid [[⊥]] \mid [[Type k]] \mid [[Level< l]] \quad \text{\thmref{safety.lean}{Value}}
\end{equation*}

\subsection{Reduction and conversion}

\begin{figure}[h]
\begin{mathpar}
  \inferrule[\ottdrulename{P-Beta}]
    {[[b ⇒ b']] \and
     [[a ⇒ a']]}
    %------------------------------%
    {[[(λx : A. b) a ⇒ b'{x ↦ a'}]]}
  \quad
  \inferrule[\ottdrulename{P-Pi}]
    {[[A ⇒ A']] \and
     [[B ⇒ B']]}
    %-------------------------%
    {[[Πx : A. B ⇒ Πx : A'. B']]}
  \quad
  \inferrule[\ottdrulename{P-Lam}]
    {[[A ⇒ A']] \and
     [[b ⇒ b']]}
    %---------------------------%
    {[[λx : A. b ⇒ λx : A'. b']]}
  \quad
  \inferrule[\ottdrulename{P-Univ}]
    {[[k ⇒ k']]}
    %--------------------%
    {[[Type k ⇒ Type k']]}
  \and
  \inferrule[\ottdrulename{P-App}]
    {[[b ⇒ b']] \quad
     [[a ⇒ a']]}
    %---------------%
    {[[b a ⇒ b' a']]}
  \quad
  \inferrule[\ottdrulename{P-Abs}]
    {[[A ⇒ A']] \and
     [[b ⇒ b']]}
    %-------------------------%
    {[[abs' A b ⇒ abs' A' b']]}
  \quad
  \inferrule[\ottdrulename{P-Level<}]
    {[[l ⇒ l']]}
    %------------------------%
    {[[Level< l ⇒ Level< l']]}
  \quad
  \inferrule[\ottdrulename{P-Var}]{~}{[[x ⇒ x]]}
  \quad
  \inferrule[\ottdrulename{P-Lvl}]{~}{[[i ⇒ i]]}
  \quad
  \inferrule[\ottdrulename{P-Mty}]{~}{[[⊥ ⇒ ⊥]]}
\end{mathpar}
\caption{Parallel reduction rules \thmref{reduction.lean}{Par,Pars}}
\label{fig:par}
\end{figure}

Rather than working directly with $\beta$-reduction,
we use parallel reduction \fbox{$[[a ⇒ b]]$},
defined in \cref{fig:par},
and its reflexive, transitive closure \fbox{$[[a ⇒* b]]$},
into which call-by-name evaluation embeds.
Similarly, instead of definitional equality,
we use conversion \fbox{$[[a ⇔ b]]$},
which is defined in terms of parallel reduction.
We begin with simple lemmas about parallel reduction.

\begin{definition}[Conversion] \thmref{reduction.lean}{Conv} \\
  $[[a ⇔ b]]$ iff there exists a $[[c]]$ such that
  $[[a ⇒* c]]$ and $[[b ⇒* c]]$
\end{definition}

\begin{lemma}[Substitution (p.r.)] \thmref{reduction.lean}{parsSubst} \label{lem:pars:subst} \\
  If $[[a ⇒* a']]$ and $[[b ⇒* b']]$,
  then $[[b{x ↦ a} ⇒* b'{x ↦ a'}]]$.
\end{lemma}

\begin{lemma}[Construction (p.r.)] \thmref{reduction.lean}{pars\{$\beta$,Pi,Abs,$\mathcal{U}$,App,Exf,Lvl\}} \label{lem:pars:cons} \\
  Analogous constructors of parallel reduction hold
  for its reflexive, transitive closure,
  \eg if $[[b ⇒* b']]$ and $[[a ⇒* a']]$,
  then $[[(λx : A. b) a ⇒* b'{x ↦ a'}]]$.
\end{lemma}

\begin{lemma}[Inversion (p.r.)] \thmref{reduction.lean}{pars\{Pi,Abs,$\mathcal{U}$,App,Exf,Lvl,Lof,Mty\}Inv} \label{lem:pars:inv} \\
  If $[[v ⇒* c]]$, then $[[c]]$ is also a value of the same syntactic shape
  such that the reduction is congruent,
  \eg if $[[λx : A. b ⇒* c]]$, then $[[c]]$ is syntactically equal to $[[λx : A'. b']]$
  for some $[[A']], [[b']]$ such that $[[A ⇒* A']], [[b ⇒* b']]$.
\end{lemma}

\iffalse
\begin{figure}
\begin{alignat*}{3}
  \hspace{-1.5em}
  &
  \begin{aligned}
    [[(Πx : A. B) ^ T]] &\triangleq [[Πx : A ^ T. B ^ T]] \\
    [[(λx : A. b) ^ T]] &\triangleq [[λx : A ^ T. b ^ T]] \\
    [[(abs' A b) ^ T]] &\triangleq [[abs' A ^ T b ^ T]]
  \end{aligned}
  & ~ &
  \begin{aligned}
    [[(Type k) ^ T]] &\triangleq [[Type k ^ T]] \\
    [[(Level< l) ^ T]] &\triangleq [[Level< l ^ T]] \\
    [[a ^ T]] &\triangleq a ~ \textit{otherwise}
  \end{aligned}
  & ~ &
  \begin{aligned}
    [[(b a) ^ T]] &\triangleq
    \begin{cases}
      [[b' ^ T {x ↦ a ^ T}]] &\textit{if } [[b]] \textit{ is } [[λx. b']] \\
      [[b ^ T a ^ T]] &\textit{otherwise}
    \end{cases} \\
    &
  \end{aligned}
\end{alignat*}
\caption{Complete development \thmref{reduction.lean}{taka}}
\label{fig:taka}
\end{figure}
\fi

Proving that conversion is transitive requires proving confluence for parallel reduction.
We use the notion of complete development \fbox{$[[a ^ T]]$} by Takahashi~\citep{takahashi},
which joins parallel reduction and proves the diamond property.
Its definition is omitted here,
but corresponds to simultaneous reduction of all redexes.

\begin{lemma}[Completion (p.r.)] \thmref{reduction.lean}{parTaka} \label{lem:par:compl}
  If $[[a ⇒ b]]$, then $[[b ⇒ a ^ T]]$.
\end{lemma}

\begin{corollary}[Diamond (p.r.)] \thmref{reduction.lean}{diamond} \label{lem:par:diamond}
  If $[[a ⇒ b]]$ and $[[a ⇒ c]]$,
  then there exists some $[[d]]$ such that $[[b ⇒ d]]$ and $[[c ⇒ d]]$.
  In particular, $[[d]]$ is $[[a ^ T]]$,
  with the reductions given by \nameref{lem:par:compl}.
\end{corollary}

\begin{theorem}[Confluence (p.r.)] \thmref{reduction.lean}{confluence} \label{lem:par:confl} \\
  If $[[a ⇒* b]]$ and $[[a ⇒* c]]$,
  then there exists some $[[d]]$ such that $[[b ⇒* d]]$ and $[[c ⇒* d]]$.
\end{theorem}

\begin{corollary}[Properties of conversion] \thmref{reduction.lean}{conv*} \label{lem:conv}
  Conversion is reflexive, symmetric, transitive, substitutive, and congruent.
  Transitivity requires \nameref{lem:par:confl};
  the remaining are straightforward
  from the corresponding properties of parallel reduction.
\end{corollary}

Inversion on parallel reduction gives syntactic consistency and injectivity of conversion.
Finally, definitional equality is equivalent to conversion,
which allows us to use them interchangeably later on.
% The right-to-left direction is proven using induction on parallel reduction,
% while the left-to-right direction is proven by induction on definitional equality,
% using the various properties of conversion.

\begin{lemma}[Syntactic consistency] \thmref{reduction.lean}{conv\{$\mathcal{U}$,Pi,Mty,Lvl\}\{$\mathcal{U}$,Pi,Mty,Lvl\}} \label{lem:par:consistency}
  If $[[v1]]$ and $[[v2]]$ have different syntactic shapes,
  then $[[v1 ⇔ v2]]$ is impossible.
\end{lemma}

\begin{lemma}[Injectivity (conv.)] \thmref{reduction.lean}{conv\{Pi,$\mathcal{U}$,Lvl\}Inv}
  \begin{enumerate}[topsep=0pt]
    \item If $[[Πx: A1. B1 ⇔ Πx: A2. B2]]$, then $[[A1 ⇔ A2]]$ and $[[B1 ⇔ B2]]$.
    \item If $[[Type k1 ⇔ Type k2]]$, then $[[k1 ⇔ k2]]$.
    \item If $[[Level< k1 ⇔ Level< k2]]$, then $[[k1 ⇔ k2]]$.
  \end{enumerate}
\end{lemma}

\begin{theorem} \thmref{typing.lean}{convEqv,eqvConv} \label{lem:eq-conv}
  $[[a = b]]$ iff $[[a ⇔ b]]$.
\end{theorem}

\subsection{Subject reduction and type safety}

To prove subject reduction,
we need the usual weakening, substitution, replacement, and regularity lemmas.
They follow from stronger forms of these lemmas involving simultaneous renaming and substitution,
whose details we omit.

\begin{lemma} \thmref{safety.lean}{wtWeaken,wtSubst,wtReplace,wtRegularity} \label{lem:wt:preservation}
  \begin{itemize}
    \item \textit{Weakening.} If $[[⊢ G]]$, $[[G ⊢ B : Type k]]$, and $[[G ⊢ a : A]]$,
      then $[[G, x : B ⊢ a : A]]$, where $[[x]]$ not in $[[a]]$, $[[A]]$.
    \item \textit{Substitution.} If $[[G ⊢ b : B]]$ and $[[G, x : B ⊢ a : A]]$,
      then $[[G ⊢ a{x ↦ b} : A{x ↦ b}]]$.
    \item \textit{Replacement.} If $[[A = B]]$, $[[G ⊢ B : Type k]]$, and $[[G, x : A ⊢ c : C]]$,
      then $[[G, x : B ⊢ c : C]]$.
    \item \textit{Regularity.} If $[[G ⊢ a : A]]$, then there exists some $[[k]]$ such that
      $[[G ⊢ A : Type k]]$.
  \end{itemize}
\end{lemma}

\iffalse
\begin{lemma}[Context well-formedness] \thmref{typing.lean}{wtWf} \label{lem:wt:wf}
  If $[[G ⊢ a : A]]$, then $[[⊢ G]]$.  
\end{lemma}

\begin{lemma}[Weakening (w.t.)] \thmref{safety.lean}{wtWeaken} \label{lem:wt:weak} \\
  If $[[⊢ G]]$, $[[G ⊢ B : Type k]]$, and $[[G ⊢ a : A]]$,
  then $[[G, x : B ⊢ a : A]]$, where $[[x]]$ is not in $[[a]]$ or $[[A]]$.
\end{lemma}

\begin{proof}
  A renaming lemma is proven by induction on the typing derivation of $[[a]]$,
  showing that applying well-scoped renamings preserves typing.
  Weakening is then the special case of a single renaming by $[[x]]$ to avoid capture.
\end{proof}

\begin{lemma}[Substitution (w.t.)] \thmref{safety.lean}{wtSubst} \label{lem:wt:subst} \\
  If $[[G ⊢ b : B]]$ and $[[G, x : B ⊢ a : A]]$,
  then $[[G ⊢ a{x ↦ b} : A{x ↦ b}]]$.
\end{lemma}

\begin{proof}
  A morphing lemma is proven by induction on the typing derivation of $[[a]]$,
  showing that applying well-typed substitutions preserves typing.
  Substitution is then the special case of a single substitution of $[[x]]$.
\end{proof}

\begin{lemma}[Replacement (w.t.)] \thmref{safety.lean}{wtReplace} \label{lem:wt:replace} \\
  If $[[A = B]]$, $[[G ⊢ B : Type k]]$, and $[[G, x : A ⊢ c : C]]$,
  then $[[G, x : B ⊢ c : C]]$.
\end{lemma}

\begin{proof}
  The morphing lemma allows us to change the context from one to the other
  as long as there is a well-typed substitution between them.
  We can show that the identity substitution is such a substitution
  by proving $[[G, x : B ⊢ x : A]]$.
  This follows from \rref{Conv},
  \nameref{lem:wt:wf} for well-typedness of $[[A]]$,
  and \nameref{lem:wt:weak} to weaken it.
\end{proof}

\begin{lemma}[Context well-typedness] \thmref{safety.lean}{wtMem} \label{lem:wt:ctxt} \\
  If $[[⊢ G]]$ and $[[x : A ∈ G]]$,
  then there exists some $[[k]]$ such that $[[G ⊢ A : Type k]]$.
\end{lemma}

\begin{proof}
  Our context membership judgement is defined inductively,
  so we proceed by induction on its derivation.
  We require \nameref{lem:wt:weak} to weaken the context of the type of the variable
  by the variable itself, followed by any other variables after it.
\end{proof}

\begin{lemma}[Regularity] \thmref{safety.lean}{wtRegularity} \label{lem:wt:reg} \\
  If $[[G ⊢ a : A]]$, then there exists some $[[k]]$ such that
  $[[G ⊢ A : Type k]]$.
\end{lemma}

\begin{proof}
  By straightforward induction on the typing derivation of $[[a]]$,
  using \nameref{lem:wt:ctxt} in the \rref*{Var} case.
\end{proof}
\fi

\begin{theorem}[Subject reduction] \thmref{safety.lean}{wtPar} \label{lem:preservation} \\
  If $[[a ⇒ b]]$ and $[[G ⊢ a : A]]$, then $[[G ⊢ b : A]]$.
\end{theorem}

\begin{proof}
  By induction on the typing derivation of $[[a]]$.
  The most complex case is when the reduction is \rref*{P-Beta},
  requiring \cref{lem:conv} and \cref{lem:wt:preservation}.
  Even so, the proof is standard,
  and the cases for the universe and level rules in \cref{fig:typing:univ}
  follow from the induction hypotheses.
\end{proof}

At this point, we are able to prove admissibility of \rref{Lam}
without its first premise, which depends only on regularity.

\begin{corollary}[\textsc{Lam'}] \thmref{safety.lean}{wtfAbs} \label{Lam'} \\
  Given $[[G ⊢ Πx : A. B : Type k]]$ and $[[G, x : A ⊢ b : B]]$,
  we have $[[G ⊢ λx : A. b : Πx : A. B]]$.
  % Inversion on the first hypothesis yields $[[G ⊢ A : Type k']]$
  % such that $[[Type k = Type k']]$.
  % By \nameref{lem:wt:reg} on the same hypothesis,
  % we obtain well-typedness of $[[Type k]]$,
  % which lets us use \rref{Conv} to show $[[G ⊢ A : Type k]]$.
  % The goal then holds by \rref{Lam}.
\end{corollary}

For progress and type safety, our notion of evaluation is
the reflexive, transitive closure \fbox{$[[a ⇝* b]]$}
of call-by-name (cbn) reduction \fbox{$[[a ⇝ b]]$},
which reduces $\beta$-redexes and head positions.
A single step of cbn reduction embeds into
a single step of parallel reduction by induction,
which allows us to use \nameref{lem:preservation}.
These proofs are also standard.

\begin{lemma}[Progress] \thmref{safety.lean}{wtProgress} \label{lem:progress} \\
  If $[[• ⊢ a : A]]$, then either $[[a]]$ is a value,
  or $[[a ⇝ b]]$ for some $[[b]]$.
\end{lemma}

\begin{theorem}[Type safety] \thmref{safety.lean}{wtSafety} \\
  If $[[• ⊢ a : A]]$ and $[[a ⇝* b]]$,
  then either $[[b]]$ is a value,
  or $[[b ⇝ c]]$ for some $[[c]]$.
\end{theorem}

\iffalse
\subsection{Progress}

\begin{figure}
\begin{mathpar}
  \inferrule*[right=\ottdrulename{N-Beta}]{~}
    {[[(λx : A. b) a ⇝ b{x ↦ a}]]}
  \qquad
  \inferrule*[right=\ottdrulename{N-App}]
    {[[b ⇝ b']]}
    %--------------%
    {[[b a ⇝ b' a]]}
  \qquad
  \inferrule*[right=\ottdrulename{N-Abs}]
    {[[b ⇝ b']]}
    %------------------------%
    {[[abs' A b ⇝ abs' A b']]}
\end{mathpar}
\caption{Call by name reduction \thmref{safety.lean}{CBN}}
\label{fig:cbn}
\end{figure}

Our notion of evaluation in the progress and type safety theorems
is the reflexive, transitive closure \fbox{$[[a ⇝* b]]$}
of call-by-name (cbn) reduction \fbox{$[[a ⇝ b]]$},
defined in \cref{fig:cbn},
which reduces $\beta$-redexes and head positions.
A single step of cbn reduction embeds into
a single step of parallel reduction by induction.

\begin{lemma} \thmref{safety.lean}{CBNpar} \\
  If $[[a ⇝ b]]$ then $[[a ⇒ b]]$.
\end{lemma}

Because cbn reduces under eliminators for functions and proofs of falsehood,
we need to know what values of function and empty types are.
The following lemmas are proven by induction,
using inversion lemmas on typing derivations as needed.

\begin{lemma}[Canonical function values] \thmref{safety.lean}{wtAbs} \label{lem:canon:fun} \\
  If $[[G ⊢ v : Πx: A. B]]$,
  then $[[v]]$ has the syntactic shape $[[λx : A. b]]$ for some $[[A]], [[b]]$.
\end{lemma}

\begin{lemma}[Canonical false values] \thmref{safety.lean}{wtMty} \label{lem:canon:false}
  There is no $[[v]]$ such that $[[G ⊢ v : ⊥]]$.
\end{lemma}

Finally, we prove progress, which with subject reduction we show type safety:
closed, well-typed terms either reduce to a value, or must continue reducing.

\begin{theorem}[Progress] \thmref{safety.lean}{wtProgress} \label{lem:progress} \\
  If $[[• ⊢ a : A]]$, then either $[[a]]$ is a value,
  or $[[a ⇝ b]]$ for some $[[b]]$.
\end{theorem}

\begin{proof}
  By induction on the typing derivation of $[[a]]$,
  using \cref{lem:canon:fun,lem:canon:false}
  in the cases for \rref{App,Abs}, respectively.
\end{proof}

\begin{theorem}[Type safety] \thmref{safety.lean}{wtSafety} \\
  If $[[• ⊢ a : A]]$ and $[[a ⇝* b]]$,
  then either $[[b]]$ is a value,
  or $[[b ⇝ c]]$ for some $[[c]]$.
\end{theorem}

\begin{proof}
  By induction on the reduction $[[a ⇝* c]]$.
  The reflexive case holds by \nameref{lem:progress}.
  In the transitive case where $[[a ⇝ b]]$ and $[[b ⇝* c]]$,
  the goal holds by the induction hypothesis on the latter reduction,
  using \nameref{lem:preservation} for well typedness of $[[b]]$
  from the former.
\end{proof}
\fi

\section{Consistency and canonicity} \label{sec:lr}

To prove consistency and canonicity,
we use a logical relation to semantically interpret closed types as sets of closed terms;
these sets are backward closed under reduction,
so if a term reduces to something in the set, then it is also in the set.
The empty type is interpreted as the empty set,
universes as sets of terms that reduce to types,
and level types as sets of terms that reduce to concrete levels.
Consistency and canonicity then follow from the fundamental soundness theorem,
which states that if a term $[[a]]$ has type $[[A]]$,
then $[[a]]$ is in the interpretation of $[[A]]$.
For instance, there is no closed term of the empty type,
since it must belong to its interpretation as an empty set, which is a contradiction.
The structure of the logical relation and the soundness proof
is adapted from the mechanization by Liu~\citep{lr-pearl}.
We cover some details here,
especially as they pertain to universes and levels.

\subsection{Logical relation for closed types}

The logical relation is written as \fbox{$[[⟦ A ⟧ i ↘ P]]$},
where $[[A]]$ is the type, $[[P]]$ is the set of terms,
and $[[i]]$ is the universe level of the type.
A set of terms $[[P]]$ is mechanized as a predicate on terms,
though we to write $[[a ∈ P]]$ in lieu of $[[P]]([[a]])$
to say that $[[a]]$ is in the set,
and we use set-builder notation in lieu of explicit abstractions.
When proving properties of the logical relation,
we require no other axioms than predicate extensionality,
which follows from function and propositional extensionality;
we explicitly mark the lemmas in which they are used with $\dagger$.

Because universes are interpreted as sets of types
which themselves have interpretations at a lower universe level,
to ensure that the interpretation is well defined,
the mechanization implements it as an inductive definition
parametrized by interpretations at lower levels,
then ties the knot by well-founded induction on levels.
For clarity and concision, we ignore these details
and present the logical relation in \cref{fig:lr:closed}
without worrying about well-foundedness.

\begin{figure}
\begin{mathpar}
  \inferrule[\ottdrulename{I-Mty}]{~}
    {[[⟦ ⊥ ⟧ i ↘ ∅]]}
  \and
  \inferrule[\ottdrulename{I-Univ}]
    {[[j < i]]}
    %---------------------------------------%
  {[[⟦ Type j ⟧ i ↘ {z | ∃ P. ⟦ z ⟧ j ↘ P}]]}
  \and
  \inferrule[\ottdrulename{I-Level<}]{~}
    {[[⟦ Level< j1 ⟧ i ↘ {z | ∃ j2. z ⇒* j2 ∧ j2 < j1}]]}
  \and
  \inferrule[\ottdrulename{I-Step}]
    {[[A ⇒ B]] \and
     [[⟦ B ⟧ i ↘ P]]}
     %--------------%
    {[[⟦ A ⟧ i ↘ P]]}
  \and
  \inferrule[\ottdrulename{I-Pi}]
    {[[⟦ A ⟧ i ↘ P1]] \and
     [[∀ y. y ∈ P1 → ∃ P2. R(y, P2)]] \\\\
     [[∀ y. ∀ P2. R(y, P2) → ⟦ B{x ↦ y} ⟧ i ↘ P2]]}
    %-------------------------------------------------------------------%
    {[[⟦ Πx : A. B ⟧ i ↘ {f | ∀ y. ∀ P2. R(y, P2) → y ∈ P1 → f y ∈ P2}]]}
\end{mathpar}
\caption{Logical relation for closed types \thmref{semantics.lean}{Interps}}
\label{fig:lr:closed}
\end{figure}

Let us get the easier cases out of the way.
The interpretation of the empty type as the empty set is given by \rref{I-Mty}.
\Rref{I-Step} backward closes the interpretation under reduction of the type,
so a type has an interpretation if it reduces to a type with an interpretation.
We show shortly that forward closure under reduction of the type also holds,
as well as backward closure under reduction of the \emph{terms} in the interpretations.%
\footnote{We do not require forward closure.}

Because we consider the interpretation of closed types only,
and we have a constructor for backward closure,
the only other constructors we need are those for normal, closed types.
In particular, we need only consider $[[Type j]]$ and $[[Level< j1]]$
with concrete levels rather than arbitrary level terms.
The interpretation of $[[Level< j1]]$ given by \rref{I-Level<}
is the set of level terms strictly less than $[[j1]]$;
more precisely, it is the set of terms that reduce to such concrete levels.
The interpretation of $[[Type j]]$ given by \rref{I-Univ}
is the set of types that have an interpretation.

The intuition behind \rref{I-Pi} for function types is that a function $[[f]]$
is in its interpretation if for every argument $[[y]]$ in the interpretation of the domain,
the application $[[f y]]$ is in the interpretation of the codomain.
Because we are dealing with dependent types,
the interpretation of the codomain varies with the argument,
so we need to ensure first that the interpretation exists
for \emph{every} argument in the interpretation of the domain,
and that $[[f y]]$ is in the \emph{particular} interpretation of the codomain.
It then sounds like we would want \rref{I-Pi'} below \thmref{semantics.lean}{interpsPi}.
%
\begin{mathpar}
  \inferrule*[right=\ottdrulename{I-Pi'}]
    {[[⟦ A ⟧ i ↘ P1]] \and
     [[∀ y. y ∈ P1 → ∃ P2. ⟦ B{x ↦ y} ⟧ i ↘ P2]]}
    %--------------------------------------------------------------------------------%
    {[[⟦ Πx : A. B ⟧ i ↘ {f | ∀ y. ∀ P2. (⟦ B{x ↦ y} ⟧ i ↘ P2) → y ∈ P1 → f y ∈ P2}]]}
\end{mathpar}

The problem is that the interpretation is not strictly positive in the conclusion,
so \rref*{I-Pi'} as a constructor is not well defined.
\Rref{I-Pi} therefore uses an auxiliary relation $[[R]]$
that relates the argument $[[y]]$ to the interpretation of the codomain $[[B{x ↦ y}]]$.
\Rref{I-Pi'} then holds by instantiating $[[R(y, P2)]]$ with $[[⟦B{x ↦ y}⟧ i ↘ P2]]$ in \rref{I-Pi}.
This is the same trick used by Liu~\citep{lr-pearl},
whose origins are documented by Anand and Rahli~\citep{mech-nuprl}.

We require of the logical relation inversion properties for each constructor,
along with properties that hold \apriori for syntactic typing:
conversion and cumulativity.
A key intermediate lemma is functionality,
\ie that the interpretation of a type is deterministic.
Cumulativity holds directly by induction on the logical relation.
To prove conversion, we begin with closures over reductions.

\begin{lemma}[Cumulativity (l.r.)] \thmref{semantics.lean}{interpsCumul} \label{lem:lr:cumul} \\
  Suppose $[[i < j]]$. If $[[⟦A⟧ i ↘ P]]$, then $[[⟦A⟧ j ↘ P]]$.
\end{lemma}

\begin{lemma}[Forward and backward closure (l.r.)] \thmref{semantics.lean}{interps\{Fwds,Bwds\}} \label{lem:lr:pars} ~
  \begin{enumerate}[topsep=0pt]
    \item If $[[⟦A⟧ i ↘ P]]$ and either $[[A ⇒ B]]$ or $[[A ⇒* B]]$,
      then $[[⟦B⟧ i ↘ P]]$.
    \item If $[[⟦B⟧ i ↘ P]]$ and either $[[A ⇒ B]]$ or $[[A ⇒* B]]$,
      then $[[⟦A⟧ i ↘ P]]$.
  \end{enumerate}
\end{lemma}

\begin{proof} ~
  \begin{enumerate}[topsep=0pt]
    \item For $[[A ⇒ B]]$, by induction on the logical relation,
      using \nameref{lem:par:diamond} in the \rref*{I-Step} case.
      \nameref{lem:pars:subst} is needed in the \rref*{I-Pi} case
      to manipulate the substitution in the function codomain.
      For $[[A ⇒* B]]$, by induction on this reduction.
    \item For $[[A ⇒ B]]$, directly by \rref{I-Step}.
      For $[[A ⇒* B]]$, by induction on this reduction. \qedhere
  \end{enumerate}
\end{proof}

\begin{corollary}[Conversion (l.r.)] \thmref{semantics.lean}{interpsConv} \\
  If $[[⟦A⟧ i ↘ P]]$ and $[[A ⇔ B]]$,
  then $[[⟦B⟧ i ↘ P]]$,
  using forward and backward closure.
\end{corollary}

The final closure lemma we need is backward closure of the terms in the interpretations.
When proving the fundamental theorem,
we encounter situations where our goal requires inclusion of a reduced term in an interpretation,
while induction hypotheses only piece together inclusion of the term before reduction.

\begin{lemma}[Backward closure] \thmref{semantics.lean}{interpsBwdsP} \label{lem:lr:back} \\
  If $[[⟦A⟧ i ↘ P]]$ and $[[a ⇒* b]]$,
  then $[[b ∈ P]]$ implies $[[a ∈ P]]$.
\end{lemma}

\begin{proof}
  By induction on the logical relation.
  In the \rref*{I-Univ} case, where $[[a]]$ and $[[b]]$ are types,
  we use backward closure from \cref{lem:lr:pars}.
\end{proof}

The inversion principles for each constructor of the logical relation
hold by induction, using properties of parallel reduction as needed.
However, it is the inversion principle for \rref{I-Pi'} that we want.
The issue lies in the set of terms of the interpretation:
if we do not yet know that the sets are unique,
then inversion on \rref{I-Pi} gives \emph{some} interpretation $[[P2]]$ of the codomain,
but we do not know whether it is \emph{the} interpretation that is required.
We solve this by proving functionality.

\begin{lemma}[Fixed-level functionality (l.r.)]$\!\!{\dagger}$ \thmref{semantics.lean}{interpsDet'} \label{lem:lr:fixed-func} \\
  If $[[⟦A⟧ i ↘ P]]$ and $[[⟦A⟧ i ↘ Q]]$, then $[[P]] = [[Q]]$.
\end{lemma}

\begin{proof}
  By induction on the first logical relation,
  then generally inversion on the second,
  except for the \rref*{I-Step} case,
  which holds directly by the induction hypothesis
  and forward closure on the second logical relation.
  The complex case is \rref*{I-Pi},
  where we must prove the two sets of terms equal,
  knowing by the induction hypotheses
  that the interpretations of the domain and codomain yield equal sets.
  Because sets are encoded as predicates,
  we need to use predicate extensionality.
  It then suffices to show that membership in one set implies membership in the other,
  which holds using the induction hypotheses.
\end{proof}

Functionality holds even with different universe levels,
the idea being that the interpretation of a type is independent
of the level at which it lives.
We are then finally able to prove the inversion property for \rref{I-Pi'}.

\begin{lemma}[Functionality (l.r.)] \thmref{semantics.lean}{interpsDet} \label{lem:lr:func} \\
  If $[[⟦A⟧ i ↘ P]]$ and $[[⟦A⟧ j ↘ Q]]$, then $[[P]] = [[Q]]$.
\end{lemma}

\begin{proof}
  By totality of the order on levels,
  either $[[i]]$ and $[[j]]$ are equal,
  or one is strictly larger than the other.
  In the latter case,
  we use \nameref{lem:lr:cumul} to lift the logical relation at the lower level to the higher level.
  Then the sets are equal by \nameref{lem:lr:fixed-func}.
\end{proof}

\begin{lemma}[Inversion on function types (l.r.)]$\!\!{\dagger}$ \thmref{semantics.lean}{interpsPiInv} \label{lem:lr:inv-pi} \\
  If $[[⟦Πx: A. B⟧ i ↘ P]]$,
  then there exists a $[[P1]]$ such that:
  \begin{enumerate}[topsep=0pt]
    \item \label{lem:inv-pi:goal:A} $[[⟦ A ⟧ i ↘ P1]]$;
    \item \label{lem:inv-pi:goal:B} $[[∀ y. y ∈ P1 → ∃ P2. ⟦ B{x ↦ y} ⟧ i ↘ P2]]$; and
    \item \label{lem:inv-pi:goal:P} $[[P]] = [[{f | ∀ y. ∀ P2. (⟦ B{x ↦ y} ⟧ i ↘ P2) → y ∈ P1 → f y ∈ P2}]]$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  By inversion on the logical relation,
  which gives $[[P1]]$ and $[[R]]$ such that:
  \begin{enumerate}[topsep=0pt,start=4]
    \item \label{lem:inv-pi:hyp:A} $[[⟦ A ⟧ i ↘ P1]]$;
    \item \label{lem:inv-pi:hyp:R} $[[∀ y. y ∈ P1 → ∃ P2. R(y, P2)]]$;
    \item \label{lem:inv-pi:hyp:B} $[[∀ y. ∀ P2. R(y, P2) → ⟦ B{x ↦ y} ⟧ i ↘ P2]]$; and
    \item \label{lem:inv-pi:hyp:P} $[[P]] = [[{f | ∀ y. ∀ P2. R(y, P2) → y ∈ P1 → f y ∈ P2}]]$.
  \end{enumerate}
  \ref{lem:inv-pi:goal:A} holds directly by \ref{lem:inv-pi:hyp:A},
  and \ref{lem:inv-pi:goal:B} holds by combining \ref{lem:inv-pi:hyp:R} and \ref{lem:inv-pi:hyp:B}.
  To show that the sets in \ref{lem:inv-pi:goal:P} and \ref{lem:inv-pi:hyp:P} are equal,
  we again use predicate extensionality.
  \begin{itemize}[topsep=0pt]
    \item \textit{\ref{lem:inv-pi:goal:P} implies \ref{lem:inv-pi:hyp:P}.}
      Supposing $[[y]]$ and $[[P2]]$,
      we have three hypotheses $[[(⟦ B{x ↦ y} ⟧ i ↘ P2) → y ∈ P1 → f y ∈ P2]]$,
      $[[R(y, P2)]]$, and $[[y ∈ P1]]$.
      From \ref{lem:inv-pi:hyp:B} on the second hypothesis,
      we have $[[⟦ B{x ↦ y} ⟧ i ↘ P2]]$,
      so we can apply the first hypothesis to get $[[f y ∈ P2]]$.
    \item \textit{\ref{lem:inv-pi:hyp:P} implies \ref{lem:inv-pi:goal:P}.}
      Supposing $[[y]]$ and $[[P2]]$,
      we have three hypotheses $[[R(y, P2) → y ∈ P1 → f y ∈ P2]]$,
      $[[⟦ B{x ↦ y} ⟧ i ↘ P2]]$, and $[[y ∈ P1]]$.
      By the first hypothesis on the second and on \ref{lem:inv-pi:hyp:R},
      there exists a $[[P2']]$ such that $[[f y ∈ P2']]$.
      From \ref{lem:inv-pi:hyp:B}, we also have $[[⟦ B{x ↦ y} ⟧ i ↘ P2']]$.
      Then by \nameref{lem:lr:func}, we have $[[P2]] = [[P2']]$, so $[[f y ∈ P2]]$.
      \qedhere
  \end{itemize}
\end{proof}

Inversion principles also hold for the other types
by induction on the logical relation.

\begin{lemma}[Inversion on universes (l.r.)] \thmref{semantics.lean}{interps$\mathcal{U}$Inv} \label{lem:lr:inv-univ} \\
  If $[[⟦Type k⟧ i ↘ P]]$ and $[[A ∈ P]]$,
  then there exists $[[j]], [[Q]]$ such that $[[k ⇒* j]]$ and $[[⟦A⟧ j ↘ Q]]$.
\end{lemma}

\begin{lemma}[Inversion on level types (l.r.)] \thmref{semantics.lean}{interpLvlInv} \label{lem:lr:inv-lvl} \\
  If $[[⟦Level< l⟧ i ↘ P]]$ and $[[k ∈ P]]$,
  then there exist $[[j2]] < [[j1]]$ such that $[[l ⇒* j1]]$ and $[[k ⇒* j2]]$.
\end{lemma}

\begin{lemma}[Inversion (l.r.)] \thmref{semantics.lean}{interpsStepInv} \label{lem:lr:inv} \\
  If $[[⟦C⟧ i ↘ P]]$, then one of the following holds: $[[C ⇒* ⊥]]$; or
  \begin{itemize}[topsep=0pt]
    \item There exist $[[A]]$ and $[[B]]$ such that $[[C ⇒* Πx: A. B]]$; or
    \item There exists $[[i]]$ such that $[[C ⇒* Type i]]$ or $[[C ⇒* Level< i]]$.
  \end{itemize}
\end{lemma}

\subsection{Fundamental soundness theorem}

Although the logical relation relates closed types to sets of closed terms,
the fundamental theorem is proven over syntactic typing of open terms,
so we need a notion of semantic typing that handles closing over the terms
in a given typing context with a simultaneous substitution.
Semantic typing is then elementhood of a term in the interpretation of its type
for any substitution that closes them both.

At this point, referring to simultaneous substitutions is inevitable.
We denote them as $[[s]]$, and write $[[s, x ↦ a]]$
for its extension by a single substitution of $[[x]]$ by $[[a]]$.
In the mechanization, semantic well-typedness of a substitution \fbox{$[[s ⊧ G]]$}
is defined similarly to semantic typing \fbox{$[[G ⊢ a : A]]$},
but the admissible rules defined in \cref{fig:sem:subst} are more convenient.

\begin{definition} \thmref{semantics.lean}{semSubst}
  A substitution $[[s]]$ is semantically well typed
  wrt context $[[G]]$ iff for every $[[x : A ∈ G]]$,
  there exist $[[i]], [[P]]$ such that
  $[[⟦A{s}⟧ i ↘ P]]$ and $[[x{s} ∈ P]]$.
\end{definition}

\begin{figure}
\begin{mathpar}
  \mprset{fraction={\cdot\cdots\cdot}}
  \inferrule*[right=\ottdrulename{I-Nil}]{~}{[[s ⊧ •]]}
  \and
  \inferrule*[right=\ottdrulename{I-Cons}]
    {[[s ⊧ G]] \and
     [[⟦A{s}⟧ i ↘ P]] \and
     [[a ∈ P]]}
    %-----------------------%
    {[[s, x ↦ a ⊧ G, x : A]]}
\end{mathpar}
\caption{Semantically well-typed substitutions \thmref{semantics.lean}{semSubst\{Nil,Cons\}}}
\label{fig:sem:subst}
\end{figure}

\begin{definition}[Semantic typing] \thmref{semantics.lean}{semWt}
  A term $[[a]]$ is semantically well typed with type $[[A]]$ under context $[[G]]$,
  written $[[G ⊧ a : A]]$, iff for every $[[s]]$ such that $[[s ⊧ G]]$,
  there exist $[[i]], [[P]]$ such that
  $[[⟦A{s}⟧ i ↘ P]]$ and $[[a{s} ∈ P]]$.
\end{definition}

The fundamental soundness theorem
states that syntactic typing implies semantic typing.
The cases corresponding to the rules in \cref{fig:typing:basic} are routine
by construction and inversion of \rref{I-Pi,I-Mty}~\citep{lr-pearl},
so we do not cover them all here.
Instead, we detail only the \rref*{I-Lam} case to highlight
where some of the above lemmas are used,
followed by the cases for the rules in \cref{fig:typing:univ}
that are unique to our system.
For concision, we skip steps involving massaging substitutions into the right shape.

\begin{theorem}[Soundness] \thmref{soundness.lean}{soundness} \label{thm:soundness}
  If $[[G ⊢ a : A]]$, then $[[G ⊧ a : A]]$.
\end{theorem}

\begin{proof}
  By induction on the typing derivation.
  In each case, we suppose that $[[s ⊧ G]]$.
  \begin{itemize}[topsep=0pt]
    \item \textit{\Rref{Lam}.}
      The relevant premises are $[[G ⊢ Πx: A. B : Type k]]$ and $[[G, x : A ⊢ b : B]]$,
      concluding with $[[G ⊢ λx : A. b : Πx: A. B]]$.
      By the induction hypothesis on the first premise,
      \cref{lem:lr:inv-univ}, and \cref{lem:lr:inv-pi},
      we have $[[⟦A{s}⟧ i ↘ P1]]$, $[[⟦ B{s, x ↦ a} ⟧ i ↘ P2]]$, and $[[a ∈ P1]]$,
      where the goal is now to show that $[[(λx : A. b) a ∈ P2]]$.
      By \rref{I-Cons} and the induction hypothesis on the second premise,
      we have $[[⟦B{s, x ↦ a}⟧ i' ↘ P2']]$ and $[[b{x ↦ a} ∈ P2']]$ for some $[[i']], [[P2']]$.
      By \nameref{lem:lr:func}, we have that $[[P2]] = [[P2']]$.
      Finally, by \nameref{lem:lr:back} on \rref{P-Beta} and $[[b{x ↦ a} ∈ P2]]$,
      we obtain $[[(λx : A. b) a ∈ P2]]$.
    \item \textit{\Rref{Univ}.}
      The premise is $[[G ⊢ k : Level< l]]$,
      concluding with $[[G ⊢ Type k : Type l]]$.
      By the induction hypothesis and \cref{lem:lr:inv-lvl},
      we have $[[i1 < i2]]$ such that $[[k{s} ⇒* i1]]$ and $[[l{s} ⇒* i2]]$.
      By cofinality, there must exist a $[[j]]$ such that $[[i2 < j]]$.
      The goal is now to show that $[[⟦Type (l{s})⟧ j ↘ {z | ∃ P. ⟦ z ⟧ i2 ↘ P}]]$
      and $[[⟦Type (k{s})⟧ i2 ↘ {z | ∃ P. ⟦ z ⟧ i1 ↘ P}]]$.
      These are both constructed using \rref{I-Univ} and \cref{lem:lr:pars}.
    \item \textit{\Rref{Level<}.}
      The premises are $[[G ⊢ Type k1 : Type l1]]$ and $[[G ⊢ k0 : Level< l0]]$,
      concluding with $[[G ⊢ Level< k0 : Type k1]]$.
      By the induction hypothesis on the first premise and \cref{lem:lr:inv-univ},
      $[[Type (k1{s})]]$ has an interpretation as a universe,
      so it remains to find a $[[P]]$ such that $[[⟦Level< (k0{s})⟧ j ↘ P]]$,
      where $[[k1{s} ⇒* j]]$.
      By the induction on the second premise and \cref{lem:lr:inv-lvl},
      we have $[[k0{s} ⇒* i]]$ for some $[[i]]$.
      Then the goal is constructed using \rref{I-Level<} and \cref{lem:lr:pars}.
    \item \textit{\Rref{Lvl}.} Straightforward by construction using \rref{I-Level<}.
    \item \textit{\Rref{Trans}.}
      The premises are $[[G ⊢ k1 : Level< k2]]$ and $[[G ⊢ k2 : Level< k3]]$,
      concluding with $[[G ⊢ k1 : Level< k3]]$.
      By the induction hypotheses on the two premises and \cref{lem:lr:inv-lvl},
      we know that $[[k1{s} ⇒* i1]]$, $[[k2{s} ⇒* i2]]$, $[[k2{s} ⇒* i2']]$, and $[[k3{s} ⇒* i3]]$
      such that $[[i1 < i2]]$ and $[[i2' < i3]]$.
      By \nameref{lem:par:confl} and \nameref{lem:par:consistency},
      it must be that $[[i2]] = [[i2']]$.
      From the second inversion, we already know that $[[Level< (k3{s})]]$ has an interpretation,
      so it remains to show that $[[k1{s} ⇒* i1]]$ and $[[k3{s} ⇒* i3]]$ such that $[[i1 < i3]]$,
      which holds by transitivity.
    \item \textit{\Rref{Cumul}.}
      The premises are $[[G ⊢ A : Type k]]$ and $[[G ⊢ k : Level< l]]$,
      concluding with $[[G ⊢ A : Type l]]$.
      By induction on the first premise and \cref{lem:lr:inv-univ},
      we have some $[[P]]$ such that $[[⟦A{s}⟧ i ↘ P]]$ and $[[k{s} ⇒* i]]$.
      By induction on the second premise and \cref{lem:lr:inv-lvl},
      we have some $[[i' < j]]$ such that $[[k{s} ⇒* i']]$ and $[[l{s} ⇒* j]]$.
      By \nameref{lem:par:confl} and \nameref{lem:par:consistency},
      it must be that $[[i]] = [[i']]$.
      By cofinality and \cref{lem:lr:pars},
      $[[Type (l{s})]]$ has an interpretation as a universe.
      It remains to show that $[[⟦A{s}⟧ j ↘ P]]$,
      which holds by \nameref{lem:lr:cumul} on $[[i < j]]$.
      \qedhere
  \end{itemize}
\end{proof}

Consistency and canonicity results then follow from the fundamental theorem as corollaries.

\begin{corollary}[Consistency] \thmref{soundness.lean}{consistency}
  There is no $[[b]]$ such that $[[• ⊢ b : ⊥]]$ holds.
  If there were, by \nameref{thm:soundness},
  we get have $[[• ⊧ b : ⊥]]$.
  Instantiating with the identity substitution,
  then inverting on the interpretation of $[[⊥]]$,
  we get $[[b ∈ ∅]]$, which is a contradiction.
\end{corollary}

\begin{corollary}[Canonicity of types] \thmref{soundness.lean}{canon$\mathcal{U}$} \label{lem:canon:univ}
  If $[[• ⊢ C : Type k]]$,
  then $[[C ⇒* Πx: A. B]]$, $[[C ⇒* Type i]]$, $[[C ⇒* Level< i]]$, or $[[C ⇒* ⊥]]$.
  By \nameref{thm:soundness},
  instantiating with the identity substitution,
  we have $[[j]], [[Q]]$ such that $[[⟦Type k⟧ j ↘ Q]]$ and $[[C ∈ Q]]$.
  By inversion on the former,
  we have $[[i]], [[P]]$ such that $[[k ⇒* i]]$ and $[[⟦C⟧ i ↘ P]]$.
  Then the goal holds by \nameref{lem:lr:inv}.
\end{corollary}

\begin{corollary}[Canonicity of levels] \thmref{soundness.lean}{canonLvl}
  If $[[• ⊢ k : Level< l]]$,
  then $[[k ⇒* i]]$ for some concrete level $[[i]]$.
  By \nameref{thm:soundness},
  instantiating with the identity substitution,
  we have $[[j]], [[P]]$ such that $[[⟦Level< l⟧ j ↘ P]]$ and $[[k ∈ P]]$.
  By inversion on the former,
  we have that $[[l ⇒* i2]]$ and $[[k ⇒* i1]]$ such that $[[i1 < i2]]$.
\end{corollary}

\section{Towards normalization} \label{sec:normalization}

One conventional way to prove normalization,
given that we already have a syntactic logical relation,
is to extend it from closed to open types and terms.
However, we have not yet found the correct interpretation for open universe types
that continues to satisfy the same properties we need
(inversion, conversion, cumulativity, functionality)
while being strong enough for the soundness proof to go through.

\iffalse
However, we quickly run into issues proving
the fundamental soundness theorem following this technique.
For now, we consider only weak normalization,
defined in terms of neutral and normal forms,
where neutral forms $[[e]]$ are elimination forms that do not reduce,
and normal forms $[[n]]$ are all terms that do not reduce.
%
\begin{align*}
  [[e, E]] &\Coloneqq [[x]] \mid [[e n]] \mid [[abs' N e]] &\text{\thmref{normal.lean}{ne}} \\
  [[n, N]] &\Coloneqq [[i]] \mid [[Πx : N. N]] \mid [[λx : N. n]] \mid [[⊥]] \mid [[Type n]] \mid [[Level< n]] \mid [[e]] &\text{\thmref{normal.lean}{nf}}
\end{align*}

\begin{definition}[Weak normalization] \thmref{normal.lean}{wne,wnf}
  \begin{itemize}[topsep=0pt]
    \item A term weakly reduces to neutral form,
      written $[[wne a]]$, if there exists $[[e]]$ such that $[[a ⇒* e]]$.
    \item A term weakly reduces to normal form,
      written $[[wnf a]]$, if there exists $[[n]]$ such that $[[a ⇒* n]]$.
  \end{itemize}
\end{definition}

The extended logical relation has an additional constructor for neutral types,
and their interpretations include weakly neutral terms.
The key property we require out of the logical relation is adequacy:
the interpretation of a type is a set that contains all weakly neutral terms,
and all terms in the set are weakly normal.
Then from the fundamental theorem,
we obtain weak normalization of well typed terms and their types.

\begin{figure}
\begin{mathpar}
  \inferrule[\ottdrulename{I'-Ne}]{~}{[[⟦E⟧ i ↘ {z | wne z}]]}
  \and
  %\inferrule[\ottdrulename{I'-Mty}]{~}
  %  {[[⟦ ⊥ ⟧ i ↘ {z | wne z}]]}
  %\and
  \inferrule[\ottdrulename{I'-Level<}]{~}
    {[[⟦ Level< n ⟧ i ↘ {z | wne z ∨ (∃ j1. ∃ j2. n ⇒* j1 ∧ z ⇒* j2 ∧ j2 < j1)}]]}
  % \and
  % \inferrule[\ottdrulename{I'-Univ}]
  %   {[[j < i]]}
  %   %---------------------------------------%
  % {[[⟦ Type j ⟧ i ↘ {z | ∃ P. ⟦ z ⟧ j ↘ P}]]}
\end{mathpar}
\caption{Logical relation for open types (excerpt)}
\label{fig:lr:open}
\end{figure}

\Cref{fig:lr:open} gives two rules from the new logical relation.
Both interpret types as a set of terms that include all weakly neutral terms,
which we require for adequacy.
For the interpretation of a neutral type in \rref{I'-Ne},
we have no further information about the type,
so its interpretation contains nothing else.
In the case of a level type, it may be an open term,
so we generalize the bound from a concrete level to a normal level term in \rref{I'-Level<}.
A term in its interpretation is either weakly neutral,
or it and the bounding level term both reduce to concrete levels
that satisfy the bounding constraint, similar to the original \rref{I-Level<}.

Before we define an interpretation for open universe types,
let us consider what we need from it when proving the fundamental theorem.
The cases involving levels go through with some modification;
we examine the case involving universes.
The definition of semantic typing remains unchanged.

\begin{claim}[Soundness]
  If $[[G ⊢ a : A]]$, then $[[G ⊧ a : A]]$.
\end{claim}

\begin{proof}[Proof attempt]
  By induction on the typing derivation.
  Suppose that $[[s ⊧ G]]$.
  \begin{itemize}[topsep=0pt]
    \item \textit{\Rref{Univ}}
      The premise is $[[G ⊢ k : Level< l]]$,
      concluding with $[[G ⊢ Type k : Type l]]$.
      By the induction hypothesis on the premise,
      followed by inversion on the interpretation of level types,
      we know that $[[wnf l{s}]]$, and either $[[wne k{s}]]$,
      or both $[[k{s}]]$ and $[[l{s}]]$ reduce to concrete levels related by inequality.
      The latter is the same situation as before,
      so we focus on the former.
      Our goal is to show that $[[Type (l{s})]]$ has an interpretation,
      and that $[[Type (k{s})]]$ belongs to it.
      We know that to satisfy adequacy,
      the interpretation must include weakly neutral terms,
      but $[[Type (k{s})]]$ is not an eliminator form and therefore not weakly neutral.
      Furthermore, there is no more information about the relationship
      between $[[k{s}]]$ and $[[l{s}]]$.
      \textcolor{red}{\textsc{Stuck!}} \qedhere
    % \item \textit{\Rref{Cumul}}
    %   Depends on \nameref{lem:lr:cumul} for the new logical relation.
  \end{itemize}
\end{proof}

As a concrete example,
suppose we have $[[G]] = [[x : Level< 0, y : Level< x]]$,
and consider $[[G ⊢ Type y : Type x]]$.
While it is a derivable typing judgement,
$[[Type x]]$ could not possibly be interpreted as a semantic universe,
since there are no levels strictly smaller than $[[0]]$,
and it is unclear what it would mean for $[[Type y]]$ to be in its interpretation.
\fi

It is also unclear whether the issue is finding the correct semantic model,
or if normalization does not hold at all,
because it depends on the syntactic presentation:
if we remove type annotations from our type theory
and present it Curry-style, is not normalizing.
While directly declaring an ill-founded level $[[x : Level< x]]$ is impossible,
we can construct such a level in an inconsistent context
using an unannotated $[[abs _]]$ eliminator.
Then it becomes possible to type the universe at this level as its own type.
\Cref{fig:type-in-type} explicitly constructs the key part of the typing derivation
for $[[Type (abs x)]] : [[Type (abs x)]]$ where $[[x]] : [[⊥]]$.
With an instance of type-in-type,
we can construct a nonnormalizing lambda term via
\eg Hurkens' paradox~\citep{hurkens}.

\begin{figure}
\begin{mathpar}
  \inferrule*[Left=\rref*{Univ}]{
  \inferrule*[Left=\rref*{Abs}]{
    \inferrule*[Left=\rref*{Level<}]{
      \inferrule*[Left=\rref*{Univ}]{
      \inferrule*[Left=\rref*{Lvl}]{0 < 1}{[[x : ⊥ ⊢ 0 : Level< 1]]}}
      {[[x : ⊥ ⊢ Type 0 : Type 1]]}
      \and
      \inferrule*[Right=\rref*{Abs}]{
      \inferrule*[]{\dots}{[[x : ⊥ ⊢ Level< 0 : Type 0]]}
      \and
      \inferrule*[Right=\rref*{Var}]{[[x : ⊥ ∈ x : ⊥]]}{[[x : ⊥ ⊢ x : ⊥]]}}
      {[[x : ⊥ ⊢ abs x : Level< 0]]}}
      {[[x : ⊥ ⊢ Level< (abs x) : Type 0]]}
    \and
    \inferrule*[Right=\rref*{Var}]{[[x : ⊥ ∈ x : ⊥]]}{[[x : ⊥ ⊢ x : ⊥]]}}
    {[[x : ⊥ ⊢ abs x : Level< (abs x)]]}}
  {[[x : ⊥ ⊢ Type (abs x) : Type (abs x)]]}
\end{mathpar}
\caption{Type-in-type in an inconsistent context}
\label{fig:type-in-type}
\end{figure}

The ability to assign different types to the term $[[abs x]]$ is key to constructing this derivation.
By requiring a type annotation that gets compared during definitional equality,
we can only construct a derivation for
$[[Type (abs' (Level< (abs' (Level< 0) x)) x)]] : [[Type (abs' (Level< 0) x)]]$,
which cannot be used as type-in-type.
For similar reasons, we cannot use $[[x]] : [[:concrete: ΠA: Type i. A]]$
to construct the ill-founded level, as the type arguments will be incomparable.
In contrast, type annotations have no influence on consistency,
as it remains provable via the logical relation on closed types
even when annotations are removed.

\section{Extensions} \label{sec:extensions}

Our type theory is intentionally minimal to focus only on the core necessities
of first-class levels and to keep the proof development small and uncluttered.
Some reasonable extensions include the remaining missing types from MLTT,
\ie dependent pairs, sums, naturals, propositional equality, and W types,
or general inductive types as in CIC~\citep{pcuic}.
However, these features and their difficulties are orthogonal from universes and levels.
Here, we instead look at extensions that augment how universes and levels behave,
some of which are validated by our current semantics,
and others which present additional challenges.

\subsection{Level operators and eliminators}

The only features missing from \lang that Agda has are a zeroth level,
a level successor operator, and a level maximum operator.
To justify them semantically,
we would impose the first two as additional existence conditions on the metalevel levels;
the third follows from the total ordering, which lets us pick the larger of two levels.

\vspace{-0.75\baselineskip}
\begin{mathpar}
  \inferrule[\ottdrulename{Zero}]
    {[[G ⊢ k : Level< l]]}
    %------------------------%
    {[[G ⊢ 0 : Level< (↑ k)]]}
  \and
  \inferrule[\ottdrulename{Succ}]
    {[[G ⊢ k : Level< l]]}
    %--------------------------%
    {[[G ⊢ ↑ k : Level< (↑ l)]]}
  \and
  \inferrule[\ottdrulename{Max}]
    {[[G ⊢ k1 : Level< l1]] \and
     [[G ⊢ k2 : Level< l2]]}
    %----------------------------------%
    {[[G ⊢ k1 ⊔ k2 : Level< (l1 ⊔ l2)]]}
\end{mathpar}

What complicates matters are the additional definitional equalities that
ensure that the maximum operator is idempotent, associative, commutative,
distributive with respect to successors,
and that $[[0]]$ is its identity element.
While these properties hold automatically at the metalevel for concrete levels,
they do not for arbitrary level expressions,
\eg $[[0 ⊔ ↑ (x ⊔ ↑ x) = ↑ ↑ x]]$.
Our notions of reduction then need to pick a direction for each equality
to reduce levels to some chosen canonical form.
We believe the mechanization to be doable but tedious.

Meanwhile, well-founded induction on levels already holds semantically,
as we need it to define our logical relation in the first place.
We can internalize it by syntactically introducing an eliminator $[[wf _]]$ for levels,
which states that a predicate $[[B]]$ holds on arbitrary levels
if we can show that it holds for a given level
when we know it holds for all smaller levels.
However, it is unclear whether such an eliminator would be useful.

\vspace{-0.75\baselineskip}
\begin{mathpar}
  \inferrule[ElimLvl]
    {[[G, z : Level< k ⊢ B : Type l]] \\\\
     [[G ⊢ b : Πx: Level< k. (Πy: Level< x. B{z ↦ y}) → B{z ↦ x}]]}
    %-------------------------------%
    {[[G ⊢ wf b : Πz : Level< k. B]]}
  \and
  \inferrule[E-ElimLvl]{~}{[[wf b k = b k (λy. wf b y)]]}
\end{mathpar}

\iffalse
For universes, the simplest form of an eliminator is a typecase operator,
matching on a type as a function type, the empty type, a universe, or a level type.
Such an operator is justified by \nameref{lem:canon:univ}.
However, it is known to introduce inconsistencies in the presence of parametrized inductive types.
In Idris~\citep{idris}, which has both typecase and inductives,
matching on an inductive with a parameter of type $\kw{Type} \to \kw{Type}$
yields a nonterminating expression%
\footnote{See issue \href{https://github.com/idris-lang/Idris2/issues/1116}{\#1116}},
and matching on an inductive with a parameter of type $\kw{Type} \to \kw{Bool}$
yields a proof of $\kw{Void}$%
\footnote{See issue \href{https://github.com/idris-lang/Idris2/issues/1326}{\#1326}}.
\fi

\subsection{Subtyping} \label{sec:subtyping}

Because levels are now terms,
subtyping necessarily involves typing to compare two levels.
In particular, a universe at a smaller level is a subtype of a one at a larger level,
while a level type bounded by a smaller level is a subtype of a one bounded by a larger level.
The former is already expressed by \rref{Cumul}, the latter by \rref{Trans}.
The additional benefit of subtyping making
function domains contravariant and codomains covariant with respect to subtyping.
Selected subtyping rules are given below,
along with an updated \rref{Conv'} rule.

\vspace{-0.75\baselineskip}
\begin{mathpar}
  \inferrule[\ottdrulename{S-Univ}]
    {[[G ⊢ k : Level< l]]}
    %-----------------------%
    {[[G ⊢ Type k ≤ Type l]]}
  \and
  \inferrule[\ottdrulename{S-Level<}]
    {[[G ⊢ k : Level< l]]}
    %---------------------------%
    {[[G ⊢ Level< k ≤ Level< l]]}
  \and
  \inferrule[\ottdrulename{S-Pi}]
    {[[G ⊢ A2 ≤ A1]] \and
     [[G, x: A1 ⊢ B1 ≤ B2]]}
    %-------------------------------%
    {[[G ⊢ Πx: A1. B1 ≤ Πx: A2. B2]]}
  \and
  \inferrule[\ottdrulename{S-Trans}]
    {[[G ⊢ A ≤ B]] \and
     [[G ⊢ B ≤ C]]}
    %-------------%
    {[[G ⊢ A ≤ C]]}
  \and
  \inferrule[\ottdrulename{S-Conv}]
    {[[A = B]]}
    %-------------%
    {[[G ⊢ A ≤ B]]}
  \and
  \inferrule[\ottdrulename{Conv'}]
    {[[G ⊢ a : A]] \and
     [[G ⊢ B : Type k]] \and
     [[G ⊢ A ≤ B]]}
    %-------------%
    {[[G ⊢ a : B]]}
\end{mathpar}

Although all of this subtyping behaviour holds semantically in our current model,
proving logical consistency is not so easy.
The simplicity of our logical relation relies on
the independence of definitional equality from typing,
along with its equivalence to conversion.
By introducing a subtyping judgement that depends on typing,
which in turn depends on subtyping, to prove consistency,
the logical relation would need to include a semantic notion of equality,
similar to the reducibility judgements used by Abel, \"Ohman, and Vezzosi~\citep{dec-conv}.

\section{Conclusion and future work} \label{sec:conclusion}

We have presented \lang, a type theory with first-class universe levels.
In contrast to existing work,
rather than level constraints being separate from the type of levels,
we combine them such that every level explicitly has a bound.
We have proven our type theory to be type safe,
and in particular that subject reduction holds.
This is in contrast to BCDE~\citep{univ-poly},
the only other formal syntactic system we know of
with universe level polymorphism beyond prenex polymorphism,
which violates subject reduction.
We have also proven our type theory to be logically consistent,
and therefore useable as a logic for writing proofs.

Proving normalization and decidability of type checking
is the next step in showing that our type theory is effectively type checkable
and thus has the potential to be a basis for theorem proving.
Whether the extended logical relation presented in \cref{sec:normalization}
can be repaired to prove normalization is unclear,
as is whether well-typed terms are normalizing at all.
Looking to existing work,
BCDE proposes allowing looping level constraints of the form $[[k]] < [[k]]$ to admit subject reduction,
but this would also permit type-in-type in a looping context and violate normalization.
Even so, we are hopeful that it holds,
as no issues with cumulative first-class levels have yet arisen in Agda.

Decidability of type checking does not hold straightforwardly from normalization,
as a type checking algorithm must incorporate the non--syntax-directed \rref{Trans,Cumul}.
It may be done separately via algorithmic subtyping,
but as seen in \cref{sec:subtyping},
a subtyping relation must depend on typing
to show that one level expression is strictly smaller than another.
The challenge lies in showing totality of a mutual typing--subtyping algorithm,
but if looping level bounds $[[k]] : [[Level< k]]$ are ruled out by normalization,
there is no reason to believe it would not be total.

\bibliographystyle{plainurl}
\bibliography{main.bib}

\end{document}